# Machine_learning XGBoost Twitch
# Proyecto para Explicar Cantidad de Viewers en Twitch Utilizando XGBoost üöÄ

Bienvenido al proyecto que utiliza XGBoost para predecir la cantidad de espectadores en Twitch. Aqu√≠ mostrar√© el proceso para modelar datos para hacer predicciones precisas. ¬°Vamos a comenzar! üéâ

## Descripci√≥n del Proyecto üìÑ

XGBoost (Extreme Gradient Boosting) es un algoritmo de aprendizaje autom√°tico basado en √°rboles de decisi√≥n. Utiliza el m√©todo de boosting, que combina varios √°rboles de decisi√≥n d√©biles para crear un modelo m√°s robusto y preciso. XGBoost optimiza la predicci√≥n minimizando un objetivo de p√©rdida mediante el uso de t√©cnicas avanzadas de optimizaci√≥n y regularizaci√≥n para mejorar el rendimiento y reducir el sobreajuste. Es conocido por su eficiencia, flexibilidad y capacidad para manejar datos estructurados y no estructurados.

## Pasos del Proyecto üõ†Ô∏è
1. Recolecci√≥n de Datos üìä
2. Preprocesamiento de Datos üßπ
3. Divisi√≥n de Datos ‚úÇÔ∏è
4. Selecci√≥n de Caracter√≠sticas üîç
5. Configuraci√≥n del Modelo ‚öôÔ∏è
6. Entrenamiento del Modelo üß†
7. Evaluaci√≥n del Modelo üìà
8. Ajuste de Hiperpar√°metros üîß
9. Validaci√≥n Cruzada üîÑ
10. Implementaci√≥n y Monitoreo üöÄ

## Detalle paso a paso:

## 1. Recolecci√≥n de Datos üìä
En este caso, usar√© los datos de las transmisiones de Twitch disponibles en Kaggle. 

[https://www.kaggle.com/datasets/ashishkumarak/twitch-reviews-daily-updated](https://www.kaggle.com/datasets/hibrahimag1/top-1000-twitch-streamers-data-may-2024)

## 2. Preprocesamiento de Datos üßπ
Limpia y prepara los datos, incluyendo la eliminaci√≥n de valores nulos, codificaci√≥n de variables categ√≥ricas y normalizaci√≥n. Esto asegura que el modelo tenga datos de alta calidad para aprender.

  2.a. **Inspecci√≥n de Datos**: Revisar los primeros registros y el resumen estad√≠stico.
   
   2.b. **Manejo de Valores Nulos**: Identificar y tratar los valores nulos en el dataset.
   
   2.c. **Codificaci√≥n de Variables Categ√≥ricas**: Convertir las variables categ√≥ricas en valores num√©ricos.
   
   2.d. **Normalizaci√≥n/Estandarizaci√≥n**: Normalizar o estandarizar las caracter√≠sticas num√©ricas.
   
   2.e. **Detecci√≥n y Manejo de Outliers**: Identificar y tratar valores at√≠picos.
   
   2.f. **Creaci√≥n de Nuevas Caracter√≠sticas**: Crear nuevas caracter√≠sticas si es necesario.

### 2.a. Inspecci√≥n de Datos: Revisar los primeros registros y el resumen estad√≠stico.
``` python
import pandas as pd
df = pd.read_csv('Twitch.csv')
# Mostrar los primeros registros
display(df.head())
```
![image](https://github.com/Cesarandres91/Machine_learning_XGBoost_Twitch/assets/102868086/16696030-3982-4e45-a094-184e68a99767)

``` python
# Resumen estad√≠stico
print(df.describe())
```
![image](https://github.com/Cesarandres91/Machine_learning_XGBoost_Twitch/assets/102868086/09af9eb4-cd82-4d21-9223-b12d9a8a567e)

``` python
# Informaci√≥n sobre el dataframe
print(df.info())
```

![image](https://github.com/Cesarandres91/Machine_learning_XGBoost_Twitch/assets/102868086/e84451bb-91ff-403f-aa95-b2c7eedb1216)

### 2.b. Manejo de Valores Nulos: Identificar y tratar los valores nulos en el dataset.

``` python
# Ejemplo de eliminaci√≥n de filas con valores nulos
#df.dropna(inplace=True)

# Alternativamente, podemos rellenar valores nulos con la media (para columnas num√©ricas) o la moda (para columnas categ√≥ricas)
# df.fillna(df.mean(), inplace=True)
# df.fillna(df.mode().iloc[0], inplace=True)

#En este caso como se trata de una variable categorica correspondiente al 2ND_MOST_STREAMED_GAME, lo completar√© con el texto "Sin informaci√≥n"

# Rellenar valores nulos en la columna '2ND_MOST_STREAMED_GAME' con 'Sin informaci√≥n'
df['2ND_MOST_STREAMED_GAME'].fillna('Sin informaci√≥n', inplace=True)

# Verificar que los valores nulos han sido completados
print(df['2ND_MOST_STREAMED_GAME'].isnull().sum())
```

### 2.c. Codificaci√≥n de Variables Categ√≥ricas: Convertir las variables categ√≥ricas en valores num√©ricos.

``` python
# Identificar variables categ√≥ricas
categorical_columns = df.select_dtypes(include=['object']).columns
print(categorical_columns)
```
![image](https://github.com/Cesarandres91/Machine_learning_XGBoost_Twitch/assets/102868086/ca1bf838-393c-48d7-98fd-cf65ac45cec5)

Para, codificar las variables categoricas usar√© Label Encoding, este m√©todo asigna un n√∫mero entero √∫nico a cada categor√≠a.

``` python
from sklearn.preprocessing import LabelEncoder

# Aplicar Label Encoding a las variables categ√≥ricas
label_encoders = {}
for column in categorical_columns:
    le = LabelEncoder()
    df[column] = le.fit_transform(df[column])
    label_encoders[column] = le

# Verificar que las variables han sido codificadas
print(df.head())
```
Este c√≥digo identifica las columnas categ√≥ricas y aplica Label Encoding a cada una de ellas. 
Tambi√©n guarda los codificadores LabelEncoder en un diccionario por si necesitamos revertir la codificaci√≥n o realizar alguna transformaci√≥n adicional en el futuro.

![image](https://github.com/Cesarandres91/Machine_learning_XGBoost_Twitch/assets/102868086/576f3f09-8695-4e90-adcf-7d97f3ea24e9)

### 2.d. Normalizaci√≥n/Estandarizaci√≥n: Normalizar o estandarizar las caracter√≠sticas num√©ricas.

Ahora utilizaremos StandardScaler de sklearn.preprocessing para estandarizar las caracter√≠sticas num√©ricas del dataset.
Esto va a identificar las columnas num√©ricas y aplicar la estandarizaci√≥n, es decir, vamos a ajustar los datos para que tengan una media de 0 y una desviaci√≥n est√°ndar de 1. 
Esto es √∫til para muchos algoritmos de machine learning que funcionan mejor cuando las caracter√≠sticas tienen una escala similar.

¬øPor qu√© es importante?, lo explico en m√°s detalle aqu√≠: [normalization_and_standardization.md](Machine_learning_XGBoost_Twitch/Otros detalles/normalization_and_standardization.md).

![image](https://github.com/Cesarandres91/Machine_learning_XGBoost_Twitch/assets/102868086/9c40d5b4-6c64-4ed4-ae46-340b6d75f1b6)

### 2.e. Detecci√≥n y Manejo de Outliers: Identificar y tratar valores at√≠picos.

Para este punto utilizaremos el m√©todo del rango intercuart√≠lico (IQR) para identificar y manejar los valores at√≠picos.
¬øPor qu√© es importante?, lo explico en m√°s detalle aqu√≠: [outlier_detection_and_handling.md](Machine_learning_XGBoost_Twitch/Otros detalles/outlier_detection_and_handling.md).

``` python
import numpy as np

# Calcular el primer cuartil (Q1) y el tercer cuartil (Q3)
Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1

# Definir l√≠mites inferior y superior
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Reemplazar outliers por los l√≠mites del IQR
df_no_outliers = df.copy()
for column in df_no_outliers.select_dtypes(include=['float64', 'int64']).columns:
    df_no_outliers[column] = np.where(df_no_outliers[column] < lower_bound[column], lower_bound[column], df_no_outliers[column])
    df_no_outliers[column] = np.where(df_no_outliers[column] > upper_bound[column], upper_bound[column], df_no_outliers[column])

# Opcional: Eliminar outliers
#df_outliers_removed = df[~outliers.any(axis=1)]

# Verificar los cambios
print(df_no_outliers.head())
```
Con esto calculamos el primer (Q1) y tercer cuartil (Q3) para cada columna.
Definimos los l√≠mites inferior y superior utilizando el IQR.
Reemplazamos los valores que est√°n por debajo del l√≠mite inferior con el valor del l√≠mite inferior y los valores que est√°n por encima del l√≠mite superior con el valor del l√≠mite superior.
Esto conserva todas las filas del dataset mientras limita el impacto de los outliers, otra opci√≥n es eliminar los outliers.

### 2.f. Creaci√≥n de Nuevas Caracter√≠sticas: Crear nuevas caracter√≠sticas si es necesario.
La creaci√≥n de nuevas caracter√≠sticas puede ayudar a mejorar el rendimiento del modelo al proporcionar informaci√≥n adicional derivada de las caracter√≠sticas existentes.

*La creaci√≥n de nuevas caracter√≠sticas debe basarse en la comprensi√≥n del problema y el conocimiento del dominio, ya que caracter√≠sticas bien dise√±adas pueden mejorar significativamente el rendimiento del modelo.

``` python
# Ratio de juegos por d√≠a activo
df_no_outliers['GAMES_PER_ACTIVE_DAY'] = df_no_outliers['TOTAL_GAMES_STREAMED'] / df_no_outliers['ACTIVE_DAYS_PER_WEEK']

# Interacci√≥n entre la cantidad de seguidores y el promedio de espectadores por transmisi√≥n
df_no_outliers['FOLLOWERS_X_VIEWERS'] = df_no_outliers['TOTAL_FOLLOWERS'] * df_no_outliers['AVG_VIEWERS_PER_STREAM']

# Porcentaje de d√≠as activos en una semana
df_no_outliers['ACTIVE_DAYS_PERCENTAGE'] = df_no_outliers['ACTIVE_DAYS_PER_WEEK'] / 7
```

## 3. Divisi√≥n de Datos ‚úÇÔ∏è

Divide los datos en conjuntos de entrenamiento y prueba. Esto nos permitir√° evaluar el rendimiento del modelo de manera objetiva.

3.a Estratificaci√≥n: Si la variable objetivo est√° desbalanceada, usar la estratificaci√≥n para asegurar que la proporci√≥n de clases se mantenga en ambos conjuntos.
3.b Escalado: Asegurarse de que las transformaciones (como la normalizaci√≥n/estandarizaci√≥n) se apliquen correctamente.
3.c Separaci√≥n de Validaci√≥n: Crear un conjunto de validaci√≥n si es necesario para ajustar los hiperpar√°metros del modelo.

``` python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Definir las caracter√≠sticas (X) y la variable objetivo (y)
X = df_no_outliers.drop('AVG_VIEWERS_PER_STREAM', axis=1)
y = df_no_outliers['AVG_VIEWERS_PER_STREAM']

# Dividir los datos en conjuntos de entrenamiento y prueba con estratificaci√≥n (si es necesario)
# Aqu√≠ no utilizamos estratificaci√≥n ya que es una variable continua. Estratificaci√≥n se usa t√≠picamente para variables categ√≥ricas.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Aplicar escalado a los datos
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Verificar las formas de los conjuntos de entrenamiento y prueba
print("Conjunto de entrenamiento:", X_train_scaled.shape, y_train.shape)
print("Conjunto de prueba:", X_test_scaled.shape, y_test.shape)
```
Aqu√≠ se define las caracter√≠sticas (X) eliminando la columna AVG_VIEWERS_PER_STREAM del dataframe y define la variable objetivo (y) como AVG_VIEWERS_PER_STREAM.
Utiliza train_test_split para dividir los datos en un conjunto de entrenamiento (80%) y un conjunto de prueba (20%), con una semilla aleatoria (random_state) de 42 para garantizar la reproducibilidad.
Verifica las formas de los conjuntos de entrenamiento y prueba.

## 4. Selecci√≥n de Caracter√≠sticas üîç
Identifica y selecciona las caracter√≠sticas relevantes que se utilizar√°n en el modelo, ser√° una ayuda para mejorar la precisi√≥n y eficiencia del modelo.
Primero, entrenaremos un modelo XGBoost inicial para obtener las importancias de las caracter√≠sticas y luego seleccionaremos las m√°s relevantes.

Correlaci√≥n de variables,
import pandas as pd
``` python
# 'df_no_outliers' es el dataframe con todas las caracter√≠sticas y sin outliers
# 'AVG_VIEWERS_PER_STREAM' es la variable objetivo

# Calcular la matriz de correlaci√≥n
correlation_matrix = df_no_outliers.corr()

# Extraer la correlaci√≥n de todas las variables con respecto a la variable objetivo
correlation_with_target = correlation_matrix['AVG_VIEWERS_PER_STREAM']

# Mostrar las correlaciones
print("Correlaci√≥n de todas las variables con respecto a la variable objetivo 'AVG_VIEWERS_PER_STREAM':")
print(correlation_with_target)
```
![image](https://github.com/Cesarandres91/Machine_learning_XGBoost_Twitch/assets/102868086/0d34f889-a161-4633-8fbc-7a4831522f16)

Para poder visualizarlo mejor:

``` python
import seaborn as sns
import matplotlib.pyplot as plt

# Configurar el tama√±o del gr√°fico
plt.figure(figsize=(12, 8))

# Crear un mapa de calor de la matriz de correlaci√≥n
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')

# Mostrar el gr√°fico
plt.title('Matriz de Correlaci√≥n')
plt.show()
```
![descarga (1)](https://github.com/Cesarandres91/Machine_learning_XGBoost_Twitch/assets/102868086/13b51fdf-5288-4603-b980-aa20f4030389)



``` python
import xgboost as xgb
from sklearn.feature_selection import SelectFromModel

# Definir un modelo XGBoost inicial
initial_model = xgb.XGBRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=6,
    subsample=0.8,
    colsample_bytree=0.8,
    objective='reg:squarederror',
    random_state=42
)

# Entrenar el modelo inicial
initial_model.fit(X_train_scaled, y_train)

# Obtener la importancia de las caracter√≠sticas
importances = initial_model.feature_importances_

# Crear un selector basado en el modelo
selector = SelectFromModel(initial_model, prefit=True)

# Transformar los datos de entrenamiento y prueba para seleccionar las caracter√≠sticas importantes
X_train_selected = selector.transform(X_train_scaled)
X_test_selected = selector.transform(X_test_scaled)

# Verificar las nuevas formas de los conjuntos de entrenamiento y prueba
print("Conjunto de entrenamiento despu√©s de la selecci√≥n de caracter√≠sticas:", X_train_selected.shape)
print("Conjunto de prueba despu√©s de la selecci√≥n de caracter√≠sticas:", X_test_selected.shape)

# Mostrar la importancia de las caracter√≠sticas
xgb.plot_importance(initial_model)
```
![image](https://github.com/Cesarandres91/Machine_learning_XGBoost_Twitch/assets/102868086/69be1f45-c289-499f-90a3-027639a006df)

## 5. Configuraci√≥n del Modelo ‚öôÔ∏è
Configura los par√°metros del modelo XGBoost. La configuraci√≥n adecuada de los par√°metros puede tener un gran impacto en el rendimiento del modelo.
Vamos a configurar el modelo XGBoost con los hiperpar√°metros iniciales y entrenarlo utilizando las caracter√≠sticas seleccionadas, para ello
-Define el modelo XGBoost con algunos hiperpar√°metros iniciales.
-Entrena el modelo utilizando el conjunto de entrenamiento con las caracter√≠sticas seleccionadas.
-Realiza predicciones sobre el conjunto de prueba.
-Eval√∫a el rendimiento del modelo utilizando el error cuadr√°tico medio (MSE).
-Muestra la importancia de las caracter√≠sticas utilizando una gr√°fica.

``` python
import xgboost as xgb
from sklearn.metrics import mean_squared_error

# Definir el modelo XGBoost con algunos hiperpar√°metros iniciales
model = xgb.XGBRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=6,
    subsample=0.8,
    colsample_bytree=0.8,
    objective='reg:squarederror',
    random_state=42
)

# Entrenar el modelo con el conjunto de entrenamiento
model.fit(X_train_selected, y_train)

# Predecir en el conjunto de prueba
y_pred = model.predict(X_test_selected)

# Evaluar el rendimiento del modelo utilizando el error cuadr√°tico medio
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse}")

# Mostrar la importancia de las caracter√≠sticas
xgb.plot_importance(model)
```
![image](https://github.com/Cesarandres91/Machine_learning_XGBoost_Twitch/assets/102868086/46dcc929-f855-43c6-94da-213f96bdc765)


Ajuste de Hiperpar√°metros
Despu√©s de entrenar el modelo inicial, puedes ajustar los hiperpar√°metros para mejorar el rendimiento del modelo. Esto se puede hacer utilizando t√©cnicas como la b√∫squeda en cuadr√≠cula (GridSearchCV) o la b√∫squeda aleatoria (RandomizedSearchCV) de sklearn.model_selection.
*GridSearchCV es una t√©cnica de optimizaci√≥n de hiperpar√°metros proporcionada por la biblioteca scikit-learn en Python. Su objetivo es encontrar la mejor combinaci√≥n de hiperpar√°metros para un modelo de machine learning a trav√©s de una b√∫squeda exhaustiva sobre un conjunto especificado de par√°metros, provee:
B√∫squeda Exhaustiva: GridSearchCV prueba todas las combinaciones posibles de los hiperpar√°metros especificados en una cuadr√≠cula (grid) de par√°metros.
Validaci√≥n Cruzada: Utiliza la validaci√≥n cruzada para evaluar el rendimiento de cada combinaci√≥n de hiperpar√°metros. La validaci√≥n cruzada divide los datos en m√∫ltiples subconjuntos y eval√∫a el modelo varias veces para obtener una estimaci√≥n robusta del rendimiento.
Selecci√≥n del Mejor Modelo: Selecciona la combinaci√≥n de hiperpar√°metros que da el mejor rendimiento seg√∫n la m√©trica de evaluaci√≥n especificada (por ejemplo, precisi√≥n, F1-score, etc.).
Facilita el Ajuste de Hiperpar√°metros: Permite ajustar autom√°ticamente los hiperpar√°metros del modelo sin tener que hacerlo manualmente, lo que puede ser tedioso y propenso a errores.

``` python
from sklearn.model_selection import GridSearchCV

# Definir el modelo XGBoost
model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)

# Definir la cuadr√≠cula de hiperpar√°metros
param_grid = {
    'n_estimators': [50, 100, 200],
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 6, 9],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0]
}

# Configurar GridSearchCV
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)

# Ajustar GridSearchCV
grid_search.fit(X_train_selected, y_train)

# Mostrar los mejores hiperpar√°metros
print(f"Best hyperparameters: {grid_search.best_params_}")

# Utilizar el mejor modelo encontrado para predecir
best_model = grid_search.best_estimator_
y_pred_best = best_model.predict(X_test_selected)

# Evaluar el rendimiento del mejor modelo utilizando el error cuadr√°tico medio
mse_best = mean_squared_error(y_test, y_pred_best)
print(f"Mean Squared Error (Best Model): {mse_best}")
```

![image](https://github.com/Cesarandres91/Machine_learning_XGBoost_Twitch/assets/102868086/f0c9c05b-71ee-4eb7-b4f2-4c11e23437c0)

Lo anterior,
Define un modelo XGBoost.
Define una cuadr√≠cula de hiperpar√°metros para explorar.
Configura y ajusta GridSearchCV para encontrar los mejores hiperpar√°metros.
Muestra los mejores hiperpar√°metros encontrados.
Utiliza el mejor modelo encontrado para predecir y evaluar su rendimiento.



## 6. Entrenamiento del Modelo üß†
Entrena el modelo con el conjunto de datos de entrenamiento. Aqu√≠ es donde el modelo aprende a hacer predicciones basadas en los datos.



## 7. Evaluaci√≥n del Modelo üìà
Eval√∫a el rendimiento del modelo utilizando el conjunto de datos de prueba y m√©tricas de evaluaci√≥n adecuadas como RMSE, MAE, etc.
``` python
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Predecir en el conjunto de prueba
y_pred = best_model.predict(X_test_selected)

# Calcular las m√©tricas de evaluaci√≥n
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Mostrar los resultados
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"Mean Absolute Error (MAE): {mae}")
print(f"R-squared (R¬≤): {r2}")
```
![image](https://github.com/Cesarandres91/Machine_learning_XGBoost_Twitch/assets/102868086/cf950ad0-c358-40f1-a468-c3210f0eb73d)

Los resultados obtenidos son bastante buenos y muestran que el modelo est√° funcionando bien

Mean Squared Error (MSE): 0.008225852874267157
El MSE es la media de los errores al cuadrado. Un valor m√°s bajo indica que las predicciones est√°n cerca de los valores reales. En este caso, 0.0082 es un valor bastante bajo, lo que sugiere que el modelo tiene buenos resultados.
Root Mean Squared Error (RMSE): 0.09069648766224168

El RMSE es la ra√≠z cuadrada del MSE y proporciona una medida de error en las mismas unidades que la variable de salida. Un RMSE de aproximadamente 0.091 indica que el error t√≠pico del modelo es peque√±o.
Mean Absolute Error (MAE): 0.052813036632756494

El MAE es la media de los errores absolutos. Un MAE de aproximadamente 0.053 indica que, en promedio, las predicciones del modelo est√°n a 0.053 unidades de los valores reales.
R-squared (R¬≤): 0.9435291447382572
El R¬≤ es una medida que indica la proporci√≥n de la varianza en la variable dependiente que es explicada por el modelo. Un R¬≤ de 0.944 sugiere que el 94.4% de la variaci√≥n en los datos es explicada por el modelo, lo cual es muy bueno.




## 8. Ajuste de Hiperpar√°metros üîß
Ajusta los hiperpar√°metros del modelo para mejorar su rendimiento. Esto puede incluir la optimizaci√≥n de par√°metros como learning rate, max depth, etc.

## 9. Validaci√≥n Cruzada üîÑ (Cross validation)
Realiza validaci√≥n cruzada para asegurar la robustez del modelo. Esto ayuda a garantizar que el modelo generalice bien a datos no vistos.

La validaci√≥n cruzada es una t√©cnica utilizada para evaluar la capacidad de generalizaci√≥n de un modelo de machine learning. 
Proporciona una estimaci√≥n m√°s robusta del rendimiento del modelo al dividir los datos en m√∫ltiples subconjuntos y entrenar y evaluar el modelo en diferentes combinaciones de estos subconjuntos.

Validaci√≥n Cruzada con XGBoost, utilizaremos la funci√≥n cross_val_score de sklearn.model_selection para realizar la validaci√≥n cruzada. 
Para esto, necesitaremos definir el modelo y usar la m√©trica adecuada (en este caso, utilizaremos el error cuadr√°tico medio negativo).

``` python
from sklearn.model_selection import cross_val_score
from sklearn.metrics import make_scorer

# Definir el modelo XGBoost con los mejores hiperpar√°metros encontrados
model = xgb.XGBRegressor(
    n_estimators=grid_search.best_params_['n_estimators'],
    learning_rate=grid_search.best_params_['learning_rate'],
    max_depth=grid_search.best_params_['max_depth'],
    subsample=grid_search.best_params_['subsample'],
    colsample_bytree=grid_search.best_params_['colsample_bytree'],
    objective='reg:squarederror',
    random_state=42
)

# Definir la m√©trica de evaluaci√≥n (error cuadr√°tico medio negativo)
scorer = make_scorer(mean_squared_error, greater_is_better=False)

# Realizar la validaci√≥n cruzada
cv_scores = cross_val_score(model, X_train_selected, y_train, cv=5, scoring=scorer)

# Calcular la media y desviaci√≥n est√°ndar de los scores
mean_cv_score = -cv_scores.mean()
std_cv_score = cv_scores.std()

# Mostrar los resultados
print(f"Cross-Validation Mean Squared Error: {mean_cv_score}")
print(f"Standard Deviation of Cross-Validation MSE: {std_cv_score}")
```

![image](https://github.com/Cesarandres91/Machine_learning_XGBoost_Twitch/assets/102868086/ef9b9af4-bef9-4c63-8e59-620252893a61)

Los resultados de la validaci√≥n cruzada indican que el modelo tiene un buen desempe√±o generalizado. Aqu√≠ est√° la interpretaci√≥n de cada m√©trica:

Cross-Validation Mean Squared Error (MSE): 0.010974917294077107

Este valor indica el error cuadr√°tico medio promedio a trav√©s de las diferentes particiones de la validaci√≥n cruzada. Un valor de aproximadamente 0.011 es bastante bajo, lo que sugiere que el modelo est√° haciendo predicciones precisas en general.
Standard Deviation of Cross-Validation MSE: 0.001366182503274942

La desviaci√≥n est√°ndar del MSE a trav√©s de las particiones es aproximadamente 0.0014. Esto es bastante bajo, lo que indica que el modelo es consistente en su rendimiento a trav√©s de las diferentes particiones de los datos.
Resumen de los Resultados

Conclusi√≥n:
El modelo XGBoost tiene un buen rendimiento predictivo en general.
El modelo es consistente y no muestra grandes variaciones en su desempe√±o a trav√©s de diferentes subconjuntos de datos, lo que sugiere una buena capacidad de generalizaci√≥n.


## 10. Implementaci√≥n y Monitoreo üöÄ
Implementa el modelo en producci√≥n y monitorea su desempe√±o en el tiempo. Es importante mantener el modelo actualizado y funcionando correctamente.

``` python
import joblib

# Guardar el mejor modelo encontrado
joblib.dump(best_model, 'best_xgboost_model.pkl')
print("Modelo guardado exitosamente.")
```
Para cargar el modelo guardado y realizar predicciones en un entorno de producci√≥n, utiliza el siguiente c√≥digo

``` python
# Cargar el modelo guardado
loaded_model = joblib.load('best_xgboost_model.pkl')
print("Modelo cargado exitosamente.")

# Realizar predicciones con el modelo cargado
new_predictions = loaded_model.predict(X_test_selected)

# Evaluar el rendimiento del modelo cargado
mse_loaded_model = mean_squared_error(y_test, new_predictions)
print(f"Mean Squared Error (Loaded Model): {mse_loaded_model}")
```

Monitoreo del Desempe√±o del Modelo,
Implementa t√©cnicas para monitorear el rendimiento del modelo en producci√≥n:

Evaluar las Predicciones Regularmente: Comparar las predicciones del modelo con los resultados reales.
Actualizar el Modelo: Reentrenar el modelo peri√≥dicamente con datos nuevos.
Alarmas y Alertas: Configurar alarmas para alertar cuando el rendimiento del modelo cae por debajo de un umbral predefinido.
Registros y Seguimiento de M√©tricas: Mantener registros de las m√©tricas de rendimiento del modelo para analizar su evoluci√≥n.

## Contribuciones ü§ù

¬°Las contribuciones son bienvenidas! Si tienes sugerencias o mejoras, por favor abre un issue o un pull request.

## Licencia üìú

Este proyecto est√° bajo la Licencia Mozilla Public License Version 2.0. Ver el archivo LICENSE para m√°s detalles.

